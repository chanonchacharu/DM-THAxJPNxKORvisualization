{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-15T15:08:16.268769Z","iopub.execute_input":"2023-09-15T15:08:16.269184Z","iopub.status.idle":"2023-09-15T15:08:16.286923Z","shell.execute_reply.started":"2023-09-15T15:08:16.269141Z","shell.execute_reply":"2023-09-15T15:08:16.285231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport json \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:08:16.291780Z","iopub.execute_input":"2023-09-15T15:08:16.292920Z","iopub.status.idle":"2023-09-15T15:08:17.292170Z","shell.execute_reply.started":"2023-09-15T15:08:16.292887Z","shell.execute_reply":"2023-09-15T15:08:17.290861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing and Data Exploration","metadata":{}},{"cell_type":"code","source":"def split_data(df: pd.DataFrame) -> pd.DataFrame:\n    df['genres'] = df['genres'].apply(lambda x: [char.replace(',','').strip() for char in str(x).split()])\n    df['tags'] = df['tags'].apply(lambda x: [char.replace(',','').strip()  for char in str(x).split()])\n    df['aired_on'] = df['aired_on'].apply(lambda x: [char.replace(',','').strip()  for char in str(x).split()])\n    return df\n\ndef custom_rating_generator(df: pd.DataFrame) -> pd.DataFrame:\n    df['watched_ratio'] = df['tot_num_user'] / df['tot_watched']\n    df['watched_ratio'] = df['watched_ratio'].apply(lambda x: round(x,3))\n    df['scored_signif'] = df['tot_user_score'] * df['watched_ratio']\n    return df\n\ndef drama_process_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n    \n    # Filtered for prefered data\n    df['year'] = df['year'].apply(lambda x: str(x))\n    \n    df = df[\n        (df['type'].isin(['Drama','Movie'])) & \n        (df['year'].isin(['2021','2022','2023']))\n    ]\n    \n    df = split_data(df)\n    df = custom_rating_generator(df)\n    \n    removed_features = [\n        'drama_id','synopsis','rank','popularity',\n        'director','sc_writer','start_dt', 'end_dt'\n    ]\n    df = df.drop(columns=removed_features,axis=1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:08:17.294601Z","iopub.execute_input":"2023-09-15T15:08:17.295234Z","iopub.status.idle":"2023-09-15T15:08:17.311634Z","shell.execute_reply.started":"2023-09-15T15:08:17.295190Z","shell.execute_reply":"2023-09-15T15:08:17.310031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess Drama Metadata Dataset\ndtha_df = drama_process_pipeline(pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/tha_drama.csv'))\ndkor_df = drama_process_pipeline(pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/kor_drama.csv'))\ndjap_df = drama_process_pipeline(pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/jap_drama.csv'))\n\n# Extract Drama Name\ntha_dname = dtha_df[dtha_df['type'] == 'Drama']['drama_name'].tolist()\nkor_dname = dkor_df[dkor_df['type'] == 'Drama']['drama_name'].tolist()\njap_dname = djap_df[djap_df['type'] == 'Drama']['drama_name'].tolist()\n\nprint(f'Thai: {dtha_df.shape[0]}, #drama := {len(tha_dname)}')\nprint(f'South Korea: {dkor_df.shape[0]}, #drama := {len(kor_dname)}')\nprint(f'Japan: {djap_df.shape[0]}, #drama := {len(jap_dname)}')\n\nglobal valid_drama_dict \n\nvalid_drama_dict = {\n    'Thailand': tha_dname,\n    'South Korea': kor_dname,\n    'Japan': jap_dname\n}\n\n# # Load the data: ignoring drama_id, rank, and pop(ularity) because we won't be using the website ranking system\n# dtha_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/tha_drama.csv').iloc[:,1:-2]\n# dkor_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/kor_drama.csv').iloc[:,1:-2]\n# djap_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/jap_drama.csv').iloc[:,1:-2]\n\n\n# # Extract Drama Name\n# tha_dname = dtha_df[dtha_df['type'] == 'Drama']['drama_name'].tolist()\n# kor_dname = dkor_df[dkor_df['type'] == 'Drama']['drama_name'].tolist()\n# jap_dname = djap_df[djap_df['type'] == 'Drama']['drama_name'].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:08:17.313265Z","iopub.execute_input":"2023-09-15T15:08:17.314615Z","iopub.status.idle":"2023-09-15T15:08:17.656061Z","shell.execute_reply.started":"2023-09-15T15:08:17.314574Z","shell.execute_reply":"2023-09-15T15:08:17.654846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dkor_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:08:17.658828Z","iopub.execute_input":"2023-09-15T15:08:17.659369Z","iopub.status.idle":"2023-09-15T15:08:17.696309Z","shell.execute_reply.started":"2023-09-15T15:08:17.659334Z","shell.execute_reply":"2023-09-15T15:08:17.695192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will preprocess that data. Firstly, we defined a function called `review_preprocess_pipeline` that extract useful information such as total number of episode the reviewer watched, which we can used to calculated the `watched_ratio`, This ratio will be used as a weighting factor to find weighted average rating score or `wrat_avg_score` reviewers gave to the drama.\n\n#### Why should we consider using a weighted score in our analysis? \nTo illustrate this, let's draw a parallel with shopping on an e-commerce website. Imagine you come across two identical products being sold by two different vendors. In most cases, you would likely opt to purchase from the vendor with a stronger reputation. This reputation can manifest in various ways: a higher number of followers, likes, or exceptionally high average review scores, such as a perfect 5.0 stars.\n\nNow, let's apply a similar line of thinking to our analysis. When it comes to reviews of a particular drama, we value input from individuals with greater credibility. This credibility comes from those who have already watched the entire drama, as they can provide a more comprehensive and informed perspective on it. Therefore, we may choose to assign more weight to reviews from viewers with a proven track record of completing the drama, just as we would preferentially buy from a trusted vendor when shopping online.","metadata":{}},{"cell_type":"code","source":"rtha_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/tha_user_reviews.csv').iloc[:,1:]\nrkor_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/kor_user_reviews.csv').iloc[:,1:]\nrjap_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/jap_user_reviews.csv').iloc[:,1:]\n\n# Create Additional Features into each Dataset as a Key to determine the associated Country of the Drama being commented\nrtha_df['Country'] = 'Thailand'\nrkor_df['Country'] = 'South Korea'\nrjap_df['Country'] = 'Japan'","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:08:17.697871Z","iopub.execute_input":"2023-09-15T15:08:17.698694Z","iopub.status.idle":"2023-09-15T15:08:18.265086Z","shell.execute_reply.started":"2023-09-15T15:08:17.698661Z","shell.execute_reply":"2023-09-15T15:08:18.263600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def review_preprocess_pipeline(\n    df: pd.DataFrame,\n    country: str\n) -> pd.DataFrame:\n    \n    # Filtered for review that is valid\n    df = df[df['title'].isin(valid_drama_dict[country])].iloc[:,1:]\n    \n    # Create Additional Features into each Dataset as a Key to determine the associated Country of the Drama being commented\n    df['country'] = country\n    \n    # Extract Number of Epsiode watched and Total Episode Number\n    df['ep_watched'] = df['ep_watched'].fillna('0 of 0 episodes seen')\n    df['tot_watched'] = df['ep_watched'].apply(lambda x: int(str(x).split(' ')[0]))\n    df['tot_ep'] = df['ep_watched'].apply(lambda x: int(str(x).split(' ')[2]))\n    \n    # Feature Engineering\n    df['watched_ratio'] = df['tot_watched'] / df['tot_ep']\n    df['watched_ratio'] = df['watched_ratio'].fillna(0.0).apply(lambda x: round(x,3))\n    \n    df['avg_score'] = df[['story','acting_cast','music','rewatch_value']].mean(axis=1)\n    df['wrat_avg_score'] = df['avg_score'] * df['watched_ratio']\n    \n    # Remove Features that wouldn't be part of the analysis \n    df = df.drop(columns=['ep_watched', 'text'], axis=1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:08:18.266807Z","iopub.execute_input":"2023-09-15T15:08:18.267148Z","iopub.status.idle":"2023-09-15T15:08:18.278614Z","shell.execute_reply.started":"2023-09-15T15:08:18.267118Z","shell.execute_reply":"2023-09-15T15:08:18.277684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Actors Processing","metadata":{}},{"cell_type":"code","source":"atha_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/tha_tha_actors.csv')\nakor_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/kor_kor_actors.csv')\najap_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/jap_jap_actors.csv')\n\natha_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:08:18.279900Z","iopub.execute_input":"2023-09-15T15:08:18.280296Z","iopub.status.idle":"2023-09-15T15:08:18.380661Z","shell.execute_reply.started":"2023-09-15T15:08:18.280266Z","shell.execute_reply":"2023-09-15T15:08:18.379572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a function to check uniqueness of the actor name\ndef check_actor_name_uniqueness(df: pd.DataFrame) -> None:\n    \n    actor_dict = {}\n    \n    for index, row in df.iterrows():\n        actor_id, actor_name = row['actor_id'], row['actor_name']\n\n        if actor_name not in actor_dict.keys():\n            actor_dict[actor_name] = {\n                'id_list': []\n            }\n\n        if actor_id not in actor_dict[actor_name]['id_list']:\n            actor_dict[actor_name]['id_list'].append(actor_id)\n\n    for key, val in actor_dict.items():\n        actor_dict[key]['nunique'] = len(actor_dict[key]['id_list'])\n\n        if actor_dict[key]['nunique'] != 1:\n            print(\"Actor name isn't unique!\")\n            return \n    \n    print(\"Actor name is UNIQUE!\")\n    return \n\n# Check the uniqueness of the actor name. Need to use them as key later-on\ncheck_actor_name_uniqueness(atha_df)\ncheck_actor_name_uniqueness(akor_df)\ncheck_actor_name_uniqueness(ajap_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:08:18.382120Z","iopub.execute_input":"2023-09-15T15:08:18.382534Z","iopub.status.idle":"2023-09-15T15:08:20.538101Z","shell.execute_reply.started":"2023-09-15T15:08:18.382499Z","shell.execute_reply":"2023-09-15T15:08:20.536912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write a function to merge the information of actor and drama (might have to be the new dataframe created from the processed reviews?) to get the information regarding the drama performance that each actor acted in. If have to use the processed data from review, then move code blocks related to actors to be after the user reviews sections","metadata":{}},{"cell_type":"code","source":"df = atha_df\n# Might changed this to the precess reviews dataset?\n\ndrama_df = dtha_df\ncountry = 'Thailand'\n\ndf = df.drop(columns=['actor_id','character_name'],axis=1)\ndf = df[df['drama_name'].isin(valid_drama_dict[country])]\n\nmerged_df = df.merge(drama_df, on='drama_name', how='left')\n\nfeatures = [\n    'actor_name', 'drama_name', 'role', 'year', 'tags', 'tags',\n    'country', 'tot_user_score', 'tot_num_user', 'tot_watched',\n    'content_rt', 'watched_ratio', 'scored_signif'\n]\n\nmerged_df = merged_df[features]\nmerged_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:17:19.884637Z","iopub.execute_input":"2023-09-15T15:17:19.885045Z","iopub.status.idle":"2023-09-15T15:17:19.929168Z","shell.execute_reply.started":"2023-09-15T15:17:19.885017Z","shell.execute_reply":"2023-09-15T15:17:19.928058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Drama Review Processing","metadata":{}},{"cell_type":"code","source":"rtha_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/tha_user_reviews.csv')\nrkor_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/kor_user_reviews.csv')\nrjap_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/jap_user_reviews.csv')\n\nrtha_df_f = review_preprocess_pipeline(rtha_df,'Thailand')\nrkor_df_f = review_preprocess_pipeline(rkor_df, 'South Korea')\nrjap_df_f = review_preprocess_pipeline(rjap_df, 'Japan')\n\nrtha_df_f.shape, rkor_df_f.shape, rjap_df_f.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:08:20.539761Z","iopub.execute_input":"2023-09-15T15:08:20.540302Z","iopub.status.idle":"2023-09-15T15:08:21.129974Z","shell.execute_reply.started":"2023-09-15T15:08:20.540256Z","shell.execute_reply":"2023-09-15T15:08:21.128735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_boxplots_with_annotations(\n    dataframe: pd.DataFrame,\n    country: str = '',\n) -> None:\n    num_columns = len(dataframe.columns)\n    num_rows = (num_columns + 2) // 3\n    \n    fig, axes = plt.subplots(nrows=num_rows, ncols=3, figsize=(16, 6 * num_rows // 2))\n    axes = axes.flatten()\n\n    for i, col in enumerate(dataframe.columns):\n        # Create a boxplot for the current column in the corresponding subplot\n        ax = axes[i]\n        ax.boxplot(dataframe[col], vert=False, sym='b.', \n                   whis=1.5, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n\n        # Outlier Calculation using IQR Method\n        q1 = np.percentile(dataframe[col], 25)\n        q3 = np.percentile(dataframe[col], 75)\n        iqr = q3 - q1\n        lower_bound = q1 - 1.5 * iqr\n        upper_bound = q3 + 1.5 * iqr\n        outliers = [x for x in dataframe[col] if x < lower_bound or x > upper_bound]\n        num_outliers = len(outliers)\n        \n        mean = np.mean(dataframe[col])\n        std_dev = np.std(dataframe[col])\n        annotation = f\"Mean: {mean:.2f}\\nStd Dev: {std_dev:.2f}\\nOutliers: {num_outliers}\"\n        ax.text(0.62, 0.80, annotation, transform=ax.transAxes, fontsize=12,\n                verticalalignment='center')\n        \n        min_score = np.min(dataframe[col])\n        max_score = np.max(dataframe[col])\n        minmax_annotation = f\"Min: {min_score:.2f}\\nMax: {max_score:.2f}\"\n        ax.text(0.62, 0.25, minmax_annotation, transform=ax.transAxes, fontsize=12,\n               verticalalignment='center')\n\n        ax.set_title(col)\n    \n    big_title = f\"{country} Boxplots\"\n    fig.suptitle(big_title, fontsize=16, y=1.02)\n    \n    for j in range(num_columns, len(axes)):\n        fig.delaxes(axes[j])\n        \n    plt.tight_layout()\n    plt.show()\n\nfeatures = [\n    'story', 'acting_cast', 'music', 'rewatch_value', 'overall',\n    'n_helpful', 'tot_watched', 'tot_ep', 'watched_ratio',\n    'avg_score', 'wrat_avg_score'\n]\n\ndraw_boxplots_with_annotations(rtha_df_f[features], 'Thailand')\n\ndraw_boxplots_with_annotations(rkor_df_f[features], 'South Korea')\n\ndraw_boxplots_with_annotations(rjap_df_f[features], 'Japan')","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:08:21.133057Z","iopub.execute_input":"2023-09-15T15:08:21.133465Z","iopub.status.idle":"2023-09-15T15:08:26.818686Z","shell.execute_reply.started":"2023-09-15T15:08:21.133435Z","shell.execute_reply":"2023-09-15T15:08:26.817049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whether to remove the outliers before or after performing a feature engineering like weighted averge score depends on the specific golas and requirement of this analysis. Upon observation of the fields related to score, we notice some outliers. However, this is something we would like to capture. The minimum and maximum values for these fields are between 1 and 10; hence, there is no hidden error in the data extraction or scoring process on the website. They are valuable insights even if they were outliers; henceforth, we won't remove it for this moment. \n\n\nAddress other features and how does outlier in those feature effect the final weighted score\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}