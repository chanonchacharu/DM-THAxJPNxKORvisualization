{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-15T14:02:19.895322Z","iopub.execute_input":"2023-09-15T14:02:19.895812Z","iopub.status.idle":"2023-09-15T14:02:19.952061Z","shell.execute_reply.started":"2023-09-15T14:02:19.895768Z","shell.execute_reply":"2023-09-15T14:02:19.950920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-09-15T14:02:19.954581Z","iopub.execute_input":"2023-09-15T14:02:19.955316Z","iopub.status.idle":"2023-09-15T14:02:20.361542Z","shell.execute_reply.started":"2023-09-15T14:02:19.955271Z","shell.execute_reply":"2023-09-15T14:02:20.360414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing and Data Exploration","metadata":{}},{"cell_type":"code","source":"def split_genres_tags(df: pd.DataFrame) -> pd.DataFrame:\n    df['genres'] = df['genres'].apply(lambda x: [char.replace(',','').strip() for char in str(x).split()])\n    df['tags'] = df['tags'].apply(lambda x: [char.replace(',','').strip()  for char in str(x).split()])\n    return df\n\ndef custom_rating_generator(df: pd.DataFrame) -> pd.DataFrame:\n    df['watched_ratio'] = df['tot_num_user'] / df['tot_watched']\n    df['watched_ratio'] = df['watched_ratio'].apply(lambda x: round(x,3))\n    df['scored_signif'] = df['tot_user_score'] * df['watched_ratio']\n    return df\n\ndef drama_process_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n    \n    # Filtered for prefered data\n    df['year'] = df['year'].apply(lambda x: str(x))\n    \n    df = df[\n        (df['type'].isin(['Drama','Movie'])) & \n        (df['year'].isin(['2021','2022','2023']))\n    ]\n    \n    df = split_genres_tags(df)\n    df = custom_rating_generator(df)\n    \n    df = df.drop(columns=['drama_id','synopsis','rank','popularity'],axis=1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-09-15T14:02:20.362931Z","iopub.execute_input":"2023-09-15T14:02:20.363490Z","iopub.status.idle":"2023-09-15T14:02:20.375347Z","shell.execute_reply.started":"2023-09-15T14:02:20.363441Z","shell.execute_reply":"2023-09-15T14:02:20.374115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess Drama Metadata Dataset\ndtha_df = drama_process_pipeline(pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/tha_drama.csv'))\ndkor_df = drama_process_pipeline(pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/kor_drama.csv'))\ndjap_df = drama_process_pipeline(pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/jap_drama.csv'))\n\n# Extract Drama Name\ntha_dname = dtha_df[dtha_df['type'] == 'Drama']['drama_name'].tolist()\nkor_dname = dkor_df[dkor_df['type'] == 'Drama']['drama_name'].tolist()\njap_dname = djap_df[djap_df['type'] == 'Drama']['drama_name'].tolist()\n\nprint(f'Thai: {dtha_df.shape[0]}, #drama := {len(tha_dname)}')\nprint(f'South Korea: {dkor_df.shape[0]}, #drama := {len(kor_dname)}')\nprint(f'Japan: {djap_df.shape[0]}, #drama := {len(jap_dname)}')\n\n# # Load the data: ignoring drama_id, rank, and pop(ularity) because we won't be using the website ranking system\n# dtha_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/tha_drama.csv').iloc[:,1:-2]\n# dkor_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/kor_drama.csv').iloc[:,1:-2]\n# djap_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/jap_drama.csv').iloc[:,1:-2]\n\n\n# # Extract Drama Name\n# tha_dname = dtha_df[dtha_df['type'] == 'Drama']['drama_name'].tolist()\n# kor_dname = dkor_df[dkor_df['type'] == 'Drama']['drama_name'].tolist()\n# jap_dname = djap_df[djap_df['type'] == 'Drama']['drama_name'].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T14:02:20.378439Z","iopub.execute_input":"2023-09-15T14:02:20.379138Z","iopub.status.idle":"2023-09-15T14:02:20.710769Z","shell.execute_reply.started":"2023-09-15T14:02:20.379087Z","shell.execute_reply":"2023-09-15T14:02:20.710005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtha_df.shape, dkor_df.shape, djap_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-15T14:02:20.711961Z","iopub.execute_input":"2023-09-15T14:02:20.712455Z","iopub.status.idle":"2023-09-15T14:02:20.720542Z","shell.execute_reply.started":"2023-09-15T14:02:20.712426Z","shell.execute_reply":"2023-09-15T14:02:20.719137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will preprocess that data. Firstly, we defined a function called `review_preprocess_pipeline` that extract useful information such as total number of episode the reviewer watched, which we can used to calculated the `watched_ratio`, This ratio will be used as a weighting factor to find weighted average rating score or `wrat_avg_score` reviewers gave to the drama.\n\n#### Why should we consider using a weighted score in our analysis? \nTo illustrate this, let's draw a parallel with shopping on an e-commerce website. Imagine you come across two identical products being sold by two different vendors. In most cases, you would likely opt to purchase from the vendor with a stronger reputation. This reputation can manifest in various ways: a higher number of followers, likes, or exceptionally high average review scores, such as a perfect 5.0 stars.\n\nNow, let's apply a similar line of thinking to our analysis. When it comes to reviews of a particular drama, we value input from individuals with greater credibility. This credibility comes from those who have already watched the entire drama, as they can provide a more comprehensive and informed perspective on it. Therefore, we may choose to assign more weight to reviews from viewers with a proven track record of completing the drama, just as we would preferentially buy from a trusted vendor when shopping online.","metadata":{}},{"cell_type":"code","source":"rtha_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/tha_user_reviews.csv').iloc[:,1:]\nrkor_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/kor_user_reviews.csv').iloc[:,1:]\nrjap_df = pd.read_csv('/kaggle/input/thai-and-japanese-drama-vs-korean-drama-dominance/jap_user_reviews.csv').iloc[:,1:]\n\n# Create Additional Features into each Dataset as a Key to determine the associated Country of the Drama being commented\nrtha_df['Country'] = 'Thailand'\nrkor_df['Country'] = 'South Korea'\nrjap_df['Country'] = 'Japan'","metadata":{"execution":{"iopub.status.busy":"2023-09-15T14:02:20.722197Z","iopub.execute_input":"2023-09-15T14:02:20.723420Z","iopub.status.idle":"2023-09-15T14:02:21.849851Z","shell.execute_reply.started":"2023-09-15T14:02:20.723345Z","shell.execute_reply":"2023-09-15T14:02:21.848626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def review_preprocess_pipeline(\n    df: pd.DataFrame\n) -> pd.DataFrame:\n    \n    # Extract Number of Epsiode watched and Total Episode Number\n    df['ep_watched'] = df['ep_watched'].fillna('0 of 0 episodes seen')\n    df['tot_watched'] = df['ep_watched'].apply(lambda x: int(str(x).split(' ')[0]))\n    df['tot_ep'] = df['ep_watched'].apply(lambda x: int(str(x).split(' ')[2]))\n    \n    # Feature Engineering\n    df['watched_ratio'] = df['tot_watched'] / df['tot_ep']\n    df['watched_ratio'] = df['watched_ratio'].fillna(0.0).apply(lambda x: round(x,3))\n    \n    df['avg_score'] = df[['story','acting_cast','music','rewatch_value']].mean(axis=1)\n    df['wrat_avg_score'] = df['avg_score'] * df['watched_ratio']\n    \n    # Remove Features that wouldn't be part of the analysis \n    \n    df = df.drop(columns=['ep_watched', 'text'], axis=1)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-09-15T14:02:21.854052Z","iopub.execute_input":"2023-09-15T14:02:21.854423Z","iopub.status.idle":"2023-09-15T14:02:21.866462Z","shell.execute_reply.started":"2023-09-15T14:02:21.854378Z","shell.execute_reply":"2023-09-15T14:02:21.864942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rtha_df_filtered = review_preprocess_pipeline(rtha_df)\nrtha_df_filtered.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T14:02:21.868370Z","iopub.execute_input":"2023-09-15T14:02:21.868843Z","iopub.status.idle":"2023-09-15T14:02:21.940631Z","shell.execute_reply.started":"2023-09-15T14:02:21.868806Z","shell.execute_reply":"2023-09-15T14:02:21.939819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\ndef draw_boxplots_with_annotations(dataframe):\n    num_columns = len(dataframe.columns)\n    num_rows = (num_columns + 2) // 3\n    \n    fig, axes = plt.subplots(nrows=num_rows, ncols=3, figsize=(16, 6 * num_rows // 2))\n    axes = axes.flatten()\n\n    for i, col in enumerate(dataframe.columns):\n        # Create a boxplot for the current column in the corresponding subplot\n        ax = axes[i]\n        ax.boxplot(dataframe[col], vert=False, sym='b.', \n                   whis=1.5, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n\n        # Outlier Calculation using IQR Method\n        q1 = np.percentile(dataframe[col], 25)\n        q3 = np.percentile(dataframe[col], 75)\n        iqr = q3 - q1\n        lower_bound = q1 - 1.5 * iqr\n        upper_bound = q3 + 1.5 * iqr\n        outliers = [x for x in dataframe[col] if x < lower_bound or x > upper_bound]\n        num_outliers = len(outliers)\n        \n        mean = np.mean(dataframe[col])\n        std_dev = np.std(dataframe[col])\n        annotation = f\"Mean: {mean:.2f}\\nStd Dev: {std_dev:.2f}\\nOutliers: {num_outliers}\"\n        ax.text(0.62, 0.80, annotation, transform=ax.transAxes, fontsize=12,\n                verticalalignment='center')\n        \n        min_score = np.min(dataframe[col])\n        max_score = np.max(dataframe[col])\n        minmax_annotation = f\"Min: {min_score:.2f}\\nMax: {max_score:.2f}\"\n        ax.text(0.62, 0.25, minmax_annotation, transform=ax.transAxes, fontsize=12,\n               verticalalignment='center')\n\n        ax.set_title(col)\n    \n    \n    for j in range(num_columns, len(axes)):\n        fig.delaxes(axes[j])\n        \n    plt.tight_layout()\n    plt.show()\n\nfeatures = [\n    'story', 'acting_cast', 'music', 'rewatch_value', 'overall',\n    'n_helpful', 'tot_watched', 'tot_ep', 'watched_ratio',\n    'avg_score', 'wrat_avg_score'\n]\n\ndraw_boxplots_with_annotations(rtha_df_filtered[features])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T14:02:44.500192Z","iopub.execute_input":"2023-09-15T14:02:44.500597Z","iopub.status.idle":"2023-09-15T14:02:46.590829Z","shell.execute_reply.started":"2023-09-15T14:02:44.500566Z","shell.execute_reply":"2023-09-15T14:02:46.589563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whether to remove the outliers before or after performing a feature engineering like weighted averge score depends on the specific golas and requirement of this analysis. Upon observation of the fields related to score, we notice some outliers. However, this is something we would like to capture. The minimum and maximum values for these fields are between 1 and 10; hence, there is no hidden error in the data extraction or scoring process on the website. They are valuable insights even if they were outliers; henceforth, we won't remove it for this moment. \n\n\nAddress other features and how does outlier in those feature effect the final weighted score\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}